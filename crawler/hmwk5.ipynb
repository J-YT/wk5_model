{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n",
      "['', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/home/jpfredette/.local/lib/python2.7/site-packages', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/local/lib/python2.7/dist-packages/IPython/extensions', '/home/jpfredette/.ipython']\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named bs4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-02be5826a503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#from bs4 import BeautifulSoup, SoupStrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#from beautifulsoup4 import BeautifulSoup, SoupStrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named bs4"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.executable)\n",
    "print (sys.path)\n",
    "import urllib\n",
    "import httplib2\n",
    "#from bs4 import BeautifulSoup, SoupStrainer\n",
    "#from beautifulsoup4 import BeautifulSoup, SoupStrainer\n",
    "import bs4\n",
    "import json\n",
    "\n",
    "http = httplib2.Http()\n",
    "sta,rsp = http.request('http://www.medisense.org.uk/do/casebank/')\n",
    "dta = []                                                      # make this a list of dicts\n",
    "idx = 0\n",
    "for link in BeautifulSoup(rsp,parse_only=SoupStrainer('a')):  # get all html <a> tags on page\n",
    "   if link.has_attr('href'):                                  # only want those with url refs\n",
    "      if \"/do/casebank/\" in link['href']:                     # eliminates cross-page refs\n",
    "         print(link['href'])                                  #  cuz only want \"do/casebank\"s\n",
    "         sta,rsp = http.request(link['href'])                 # read casebank patient page\n",
    "         soup = BeautifulSoup(rsp,'html.parser')\n",
    "         pn = (link['href'].split('/')[-1])                   # patient name comes from url\n",
    "         si = (soup.find('student-instructions')).get_text()  # student-instruction text\n",
    "         pi = (soup.find('patient-instructions')).get_text()  # patient-instruction text\n",
    "         ei = (soup.find('examiner-instructions')).get_text() # examiner-instruction text\n",
    "         print (idx)\n",
    "         print (pn)\n",
    "         print (si)\n",
    "         print (pi)\n",
    "         print (ei)\n",
    "         dta.append({\"cid\":idx,\"pnm\":pn,\"sin\":si,\"pin\":pi,\"ein\":ei})\n",
    "         idx += 1\n",
    "      #endif\n",
    "    #endif\n",
    "#endfor\n",
    "with open('dta.json','w') as pt2outfil:\n",
    "   json.dump(dta,pt2outfil)\n",
    "           #pt2pag = urllib.request.urlopen(link['href'])\n",
    "           #pagtxt = pt2pag.read(300)\n",
    "           #pagtxt = pt2pag.read().decode('utf-8')\n",
    "           #pagtxt = \"student-\"+pt2pag.read().decode('utf-8')\n",
    "           #pagtxt = html.unescape(pagtxt)\n",
    "           #print (pagtxt)\n",
    "           #soup = BeautifulSoup(link['href'], parse_only=SoupStrainer('student'))\n",
    "           # status,response = http.request(link['href'])\n",
    "           #result = re.match(\"student-\",pagtxt)\n",
    "           #print (result)\n",
    "           #result = re.match(\"Ste Roid\",pagtxt)\n",
    "           #print (result)\n",
    "           #print (response)\n",
    "           # soup = BeautifulSoup(response,'html.parser')\n",
    "           #print (soup.prettify())\n",
    "           #soup.find(id=\"accordion2\")\n",
    "           #soup.get_text()\n",
    "           #print (soup.find_all('p'))\n",
    "           # si = (soup.find('student-instructions'))\n",
    "           # pi = (soup.find('patient-instructions'))\n",
    "           # ei = (soup.find('examiner-instructions'))\n",
    "           #print (si.get_text())\n",
    "           #print (pi.get_text())\n",
    "           #print (ei.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
